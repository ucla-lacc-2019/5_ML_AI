{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discription: This is for practice of Machine Learning module in LACC 2019\n",
    "# In this mini-project, you will load the MNIST dataset images and use SVM and CNN \n",
    "# for hand-written digitsclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # read all images in MNIST, shape the data and save as \"data\"/\"label\"\n",
    "    data = np.empty((42000,28,28,1),dtype=\"float32\")\n",
    "    label = np.empty((42000,),dtype=\"uint8\")\n",
    "    imgs = os.listdir(\"./mnist\")\n",
    "    \n",
    "    num = len(imgs)\n",
    "    for i in range(num):\n",
    "        img = Image.open(\"./mnist/\"+imgs[i])\n",
    "        \n",
    "        # convert the image to numpy array (hint: numpy.asarray, dtype=\"float32\")\n",
    "        # store the images in variable \"data\", store the labels in variable \"label\"\n",
    "        # hint: for labels, you can use the list imgs in line 5, try to split it to get the labels\n",
    "        arr = np.asarray(img,dtype=\"float32\")\n",
    "        data[i,:,:,0] = arr\n",
    "        label[i] = int(imgs[i].split('.')[0])\n",
    "        \n",
    "    data /= np.max(data) # Nornalize and centralizae the data\n",
    "    data -= np.mean(data)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label = load_data()\n",
    "print(data.shape)\n",
    "# data = data.reshape(len(data), 28*28, 1, 1)\n",
    "# data = np.squeeze(data)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the original dataset and then split it into training set and testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "nb_class = 10\n",
    "label = utils.to_categorical(label, nb_class) # Convert the original labels into one-hot labels\n",
    "# Split the dataset into training set and test set, test size is 10000\n",
    "\n",
    "#######################\n",
    "\n",
    "X_train, X_test, y_train, y_test =\n",
    "# Your code here\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, ReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Creating a Sequential Model and adding the layers \n",
    "def create_model():\n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    # add model layers\n",
    "    # Conv2D(8,5x5) - Batchnorm - Dropout - Relu\n",
    "    # Conv2D(8,3x3) - Batchnorm - Dropout - Relu\n",
    "    # MaxPooling(2*2)\n",
    "    # Conv2D(16,3x3) - Batchnorm - Dropout - Relu\n",
    "    # Conv2D(16,3x3) - Batchnorm - Dropout - Relu\n",
    "    # Flatten - Dense(128) - Batchnorm - Dropout - Relu - Dense(128) - Softmax\n",
    "    \n",
    "    #######################\n",
    "    model.add(Conv2D(8, kernel_size=(5,5), input_shape=(28,28,1))) \n",
    "    # Your code here\n",
    "    \n",
    "    #######################\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(X_train, y_train, batch_size=64, validation_data=(X_test, y_test),\n",
    "          epochs=10, callbacks=[early_stopping])\n",
    "pickle.dump(model, open(\"./model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the CNN model you trained\n",
    "#######################\n",
    "\n",
    "# Your code here\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    # This function prints and plots the confusion matrix.\n",
    "    # Normalization can be applied by setting `normalize=True`.\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        # print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        # print('Confusion matrix, without normalization')\n",
    "        pass\n",
    "    # print(cm)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model use the matrices you have learnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
